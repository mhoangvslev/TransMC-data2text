{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "import json\n",
    "import xmltodict\n",
    "import glob\n",
    "        \n",
    "class webNLG_DATASET(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.category_list = []\n",
    "        self.modifiedtripleset_list = []\n",
    "        self.text_list = []            \n",
    "        \n",
    "        xml_files = glob.glob(data_path+'*')\n",
    "        for xml_file in xml_files:        \n",
    "            with open(xml_file,'r') as f:\n",
    "                xmlString = f.read()\n",
    "            dict_data = xmltodict.parse(xmlString)['benchmark']['entries']['entry']\n",
    "            if not isinstance(dict_data, list):\n",
    "                dict_data = [dict_data]                \n",
    "\n",
    "            # challenge version\n",
    "            for i in range(len(dict_data)):\n",
    "                y=dict_data[i]\n",
    "                self.category_list.append(y['@category'])\n",
    "\n",
    "                self.modifiedtripleset_list.append(y['modifiedtripleset']['mtriple'])\n",
    "                z = y['lex']\n",
    "                if isinstance(z, list):\n",
    "                    z = z[0]\n",
    "                self.text_list.append(z['#text'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.category_list)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        triple_total = []\n",
    "        if isinstance(self.modifiedtripleset_list[idx], list):\n",
    "            for triple_list in self.modifiedtripleset_list[idx]:\n",
    "                triple_total += triple_list.split('|')\n",
    "        else:\n",
    "            triple_total += self.modifiedtripleset_list[idx].split('|')\n",
    "            \n",
    "        triple = [x.strip() for x in triple_total]\n",
    "        \n",
    "        return self.category_list[idx], triple, self.text_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/data/private/WebNLG-models/chimera-master/data/WebNLG/raw/test/'\n",
    "webNLG_data = webNLG_DATASET(data_path)\n",
    "dataloader = DataLoader(webNLG_data, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./prediction/challenge/reference.txt','w')\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    cate, triple, text = sample_batched\n",
    "    f.write(text[0]+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at /data/private/GPT/openai-gpt2/base/ and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "my_model = webmodel().cuda()\n",
    "model_path = '/data/private/WebNLG-models/simple_model/pretrained/try_1/1'\n",
    "my_model.load_state_dict(torch.load(model_path + '/model.bin'))\n",
    "my_model.eval()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([50256, 50259, 50256, 50257, 50258],\n",
       " ['<|endoftext|>', '<tr>', '<|endoftext|>', '<S>', '<c>'],\n",
       " 50257)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.tokenizer.all_special_ids, my_model.tokenizer.all_special_tokens, my_model.tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1862"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('prediction/prediction_1.txt')\n",
    "f2 = open('prediction/reference.txt')\n",
    "texts = f.readlines()\n",
    "refs = f2.readlines()\n",
    "f.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in range(len(refs)):\n",
    "    text = texts[i]\n",
    "    ref = refs[i]\n",
    "    x1 = my_model.tokenizer.encode(text.strip())\n",
    "    x2 = my_model.tokenizer.encode(ref.strip())\n",
    "    if len(x2) > max_len:\n",
    "        max_len = len(x2)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.tokenizer.encode('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50258, 50256, 50257, 50256, 50259]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.END_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50256, '<|endoftext|>')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.tokenizer.eos_token_id,my_model.tokenizer.decode(50256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('prediction/reference.txt')\n",
    "texts = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open('prediction/enter_reference.txt', 'w')\n",
    "for text in texts:\n",
    "    f2.write(text+'\\n')\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('prediction/prediction_1.txt')\n",
    "texts = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open('prediction/modify_prediction_1.txt', 'w')\n",
    "for text in texts:\n",
    "    f2.write(text.replace('_', ' ').replace('@',''))\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
