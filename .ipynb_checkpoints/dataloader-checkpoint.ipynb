{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open('dataset/trainset.csv', 'r')\n",
    "# f = open('e2e-dataset/testset_w_refs.csv', 'r')\n",
    "r = csv.reader(f)\n",
    "\n",
    "cond = []\n",
    "sentence = []\n",
    "for line in r:\n",
    "    cond.append(line[0])\n",
    "    sentence.append(line[1])    \n",
    "    \n",
    "typ_list = {}\n",
    "for k in range(1, len(cond)):\n",
    "    cond_set=cond[k].split(',')\n",
    "    for m in range(len(cond_set)):\n",
    "        cond_set[m] = cond_set[m].strip()\n",
    "        pos = cond_set[m].index('[')\n",
    "        if cond_set[m][:pos] in typ_list.keys():\n",
    "            typ_list[cond_set[m][:pos]].add(cond_set[m][pos+1:-1])\n",
    "        else:            \n",
    "            typ_list[cond_set[m][:pos]] = {cond_set[m][pos+1:-1]}\n",
    "            \n",
    "#     print(k, typ_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('name[The Rice Boat], food[English], priceRange[less than £20], customer rating[low], area[riverside], familyFriendly[yes], near[Express by Holiday Inn]',\n",
       " 'The family friendly The Rice Boat is located on the riverside, near the Express by Holiday Inn, serving English cuisine below £20 with a customer rating.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond[2106], sentence[2106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x=pd.read_csv('dataset/testset_w_refs.csv')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name[Blue Spice], eatType[coffee shop], area[city centre]'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x.columns, x['mr'][0], x['ref'][0]\n",
    "x['mr'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name {'The Vaults', 'Aromi', 'Green Man', 'The Cambridge Blue', 'Loch Fyne', 'Bibimbap House', 'Taste of Cambridge', 'Blue Spice', 'Midsummer House', 'The Golden Curry', 'The Wrestlers', 'The Waterman', 'Alimentum', 'Zizzi', 'Fitzbillies', 'The Plough', 'The Twenty Two', 'The Punter', 'The Cricketers', 'The Rice Boat', 'The Phoenix', 'Cotto', 'The Mill', 'Wildwood', 'Clowns', 'The Eagle', 'The Olive Grove', 'Cocum', 'The Dumpling Tree', 'Strada', 'Browns Cambridge', 'Giraffe', 'Travellers Rest Beefeater', 'The Golden Palace'} 34\n",
      "eatType {'coffee shop', 'pub', 'restaurant'} 3\n",
      "priceRange {'£20-25', 'moderate', 'cheap', 'more than £30', 'high', 'less than £20'} 6\n",
      "customer rating {'average', 'low', '3 out of 5', '1 out of 5', '5 out of 5', 'high'} 6\n",
      "near {'Café Sicilia', 'Avalon', 'The Six Bells', 'Café Rouge', 'The Portland Arms', 'The Rice Boat', 'Burger King', 'Ranch', 'Rainbow Vegetarian Café', 'Crowne Plaza Hotel', 'Clare Hall', 'Café Adriatic', 'Café Brazil', 'The Bakers', 'The Sorrento', 'Yippee Noodle Bar', 'Express by Holiday Inn', 'All Bar One', 'Raja Indian Cuisine'} 19\n",
      "food {'Fast food', 'Japanese', 'French', 'Chinese', 'English', 'Indian', 'Italian'} 7\n",
      "area {'riverside', 'city centre'} 2\n",
      "familyFriendly {'yes', 'no'} 2\n"
     ]
    }
   ],
   "source": [
    "for k, v in typ_list.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class e2eDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): csv 파일의 경로\n",
    "        \"\"\"\n",
    "        self.dataset = pd.read_csv(csv_file)\n",
    "        self.columns = self.dataset.columns\n",
    "        self.conditions = self.dataset[self.columns[0]]\n",
    "        self.sentences = self.dataset[self.columns[1]]\n",
    "        \n",
    "        self.typ_list = {}\n",
    "        for k in range(len(self.conditions)):\n",
    "            cond_set = self.conditions[k].split(',')\n",
    "            for m in range(len(cond_set)):\n",
    "                cond_set[m] = cond_set[m].strip()\n",
    "                pos = cond_set[m].index('[')\n",
    "                if cond_set[m][:pos] in self.typ_list.keys():\n",
    "                    self.typ_list[cond_set[m][:pos]].add(cond_set[m][pos+1:-1])\n",
    "                else:            \n",
    "                    self.typ_list[cond_set[m][:pos]] = {cond_set[m][pos+1:-1]}        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.conditions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cond = self.conditions[idx]\n",
    "        sen = self.sentences[idx]\n",
    "\n",
    "        return cond, sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_dataset = e2eDataset(csv_file='dataset/trainset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('name[The Vaults], eatType[pub], priceRange[more than £30], customer rating[5 out of 5], near[Café Adriatic]',\n",
       "  'The Vaults pub near Café Adriatic has a 5 star rating.  Prices start at £30.'),\n",
       " {'name': {'Alimentum',\n",
       "   'Aromi',\n",
       "   'Bibimbap House',\n",
       "   'Blue Spice',\n",
       "   'Browns Cambridge',\n",
       "   'Clowns',\n",
       "   'Cocum',\n",
       "   'Cotto',\n",
       "   'Fitzbillies',\n",
       "   'Giraffe',\n",
       "   'Green Man',\n",
       "   'Loch Fyne',\n",
       "   'Midsummer House',\n",
       "   'Strada',\n",
       "   'Taste of Cambridge',\n",
       "   'The Cambridge Blue',\n",
       "   'The Cricketers',\n",
       "   'The Dumpling Tree',\n",
       "   'The Eagle',\n",
       "   'The Golden Curry',\n",
       "   'The Golden Palace',\n",
       "   'The Mill',\n",
       "   'The Olive Grove',\n",
       "   'The Phoenix',\n",
       "   'The Plough',\n",
       "   'The Punter',\n",
       "   'The Rice Boat',\n",
       "   'The Twenty Two',\n",
       "   'The Vaults',\n",
       "   'The Waterman',\n",
       "   'The Wrestlers',\n",
       "   'Travellers Rest Beefeater',\n",
       "   'Wildwood',\n",
       "   'Zizzi'},\n",
       "  'eatType': {'coffee shop', 'pub', 'restaurant'},\n",
       "  'priceRange': {'cheap',\n",
       "   'high',\n",
       "   'less than £20',\n",
       "   'moderate',\n",
       "   'more than £30',\n",
       "   '£20-25'},\n",
       "  'customer rating': {'1 out of 5',\n",
       "   '3 out of 5',\n",
       "   '5 out of 5',\n",
       "   'average',\n",
       "   'high',\n",
       "   'low'},\n",
       "  'near': {'All Bar One',\n",
       "   'Avalon',\n",
       "   'Burger King',\n",
       "   'Café Adriatic',\n",
       "   'Café Brazil',\n",
       "   'Café Rouge',\n",
       "   'Café Sicilia',\n",
       "   'Clare Hall',\n",
       "   'Crowne Plaza Hotel',\n",
       "   'Express by Holiday Inn',\n",
       "   'Rainbow Vegetarian Café',\n",
       "   'Raja Indian Cuisine',\n",
       "   'Ranch',\n",
       "   'The Bakers',\n",
       "   'The Portland Arms',\n",
       "   'The Rice Boat',\n",
       "   'The Six Bells',\n",
       "   'The Sorrento',\n",
       "   'Yippee Noodle Bar'},\n",
       "  'food': {'Chinese',\n",
       "   'English',\n",
       "   'Fast food',\n",
       "   'French',\n",
       "   'Indian',\n",
       "   'Italian',\n",
       "   'Japanese'},\n",
       "  'area': {'city centre', 'riverside'},\n",
       "  'familyFriendly': {'no', 'yes'}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2e_dataset[0], e2e_dataset.typ_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(e2e_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "from model import *\n",
    "my_model = mymodel()\n",
    "my_model.eval()\n",
    "my_model.load_state_dict(torch.load('./gen_model/final/model'))\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 4, 6]\n",
      "[0, 1, 2, 3, 5, 6, 7]\n",
      "[0, 3, 4, 6, 7]\n",
      "[0, 1, 2, 3, 5, 6]\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "[0, 1, 2, 4, 6, 7]\n",
      "[0, 2, 4, 5, 6, 7]\n",
      "[0, 2, 3, 4, 5, 6]\n",
      "[0, 2, 6]\n",
      "[0, 2, 3, 4, 7]\n",
      "[0, 2, 5, 6, 7]\n",
      "[0, 1, 2, 3, 5, 6]\n",
      "[0, 2, 4, 5, 6]\n",
      "[0, 2, 5, 6]\n",
      "[0, 2, 4, 5]\n",
      "[0, 2, 3, 4, 5, 7]\n",
      "[0, 2, 4, 6]\n",
      "[0, 1, 2, 3, 4, 5, 7]\n",
      "[0, 1, 2, 3, 5, 6]\n",
      "[0, 2, 3, 6]\n",
      "[0, 2, 4, 5, 7]\n",
      "[0, 1, 2, 3, 5, 6]\n",
      "[0, 2, 3, 5, 6]\n",
      "[0, 2, 3, 4, 6]\n",
      "[0, 1, 3, 4, 5, 6, 7]\n",
      "[0, 2, 3, 4]\n",
      "[0, 2, 3, 6, 7]\n",
      "[0, 1, 2, 3, 4, 5, 7]\n",
      "[0, 1, 2, 3, 4, 6, 7]\n",
      "[0, 3, 4, 5, 6]\n",
      "[0, 1, 2, 3, 4, 6]\n",
      "[0, 2, 3, 4, 5]\n",
      "[0, 1, 2, 3, 5, 6, 7]\n",
      "[0, 2, 7]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "[0, 2, 4, 6]\n",
      "[0, 1, 3, 5, 6]\n",
      "[0, 1, 2, 3, 5, 6]\n",
      "[0, 1, 2, 3, 5]\n",
      "[0, 2, 3, 4, 6, 7]\n",
      "[0, 2, 4, 5, 6]\n",
      "[0, 1, 2, 4, 6]\n",
      "[0, 1, 3, 4, 5, 6]\n",
      "[0, 2, 3, 5, 7]\n",
      "[0, 2, 4, 5, 6, 7]\n",
      "[0, 1, 3, 4, 5, 6]\n",
      "[0, 1, 2, 4, 5]\n",
      "[0, 2, 3, 5, 6]\n",
      "[0, 2, 3, 4, 5, 6, 7]\n",
      "[0, 1, 4, 6, 7]\n",
      "[0, 3, 4]\n",
      "[0, 3, 6, 7]\n",
      "[0, 2, 4, 5, 7]\n",
      "[0, 1, 2, 4, 5, 7]\n",
      "[0, 3, 5, 6]\n",
      "[0, 2, 6]\n",
      "[0, 2, 4, 5, 7]\n",
      "[0, 1, 2, 3, 4, 6, 7]\n",
      "[0, 1, 2, 3, 6]\n",
      "[0, 1, 3, 4, 6]\n",
      "[0, 2, 3, 4, 5, 6, 7]\n",
      "[0, 2, 4, 5, 6, 7]\n",
      "[0, 2, 3, 4, 5, 6]\n",
      "[0, 1, 4, 6]\n",
      "[0, 2, 5, 7]\n",
      "[0, 2, 3, 5, 7]\n",
      "[0, 1, 2, 5, 6]\n",
      "[0, 1, 2, 4, 5, 6]\n",
      "[0, 2, 3, 4, 5, 6, 7]\n",
      "[0, 1, 2, 4, 7]\n",
      "[0, 2, 4, 6, 7]\n",
      "[0, 2, 4, 5, 6, 7]\n",
      "[0, 2, 5]\n",
      "[0, 1, 2, 4, 5, 6, 7]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 2, 3, 4, 5, 6, 7]\n",
      "[0, 1, 2, 4, 7]\n",
      "[0, 2, 3, 6]\n",
      "[0, 2, 5, 6]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 2, 3, 4, 5, 6]\n",
      "[0, 2, 3, 4, 5, 6, 7]\n",
      "[0, 2, 3, 5, 6]\n",
      "[0, 1, 2, 3, 5, 6, 7]\n",
      "[0, 2, 3, 4, 5, 6, 7]\n",
      "[0, 1, 2, 4, 6, 7]\n",
      "[0, 2, 4, 5, 6]\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "[0, 1, 2, 4, 5, 6, 7]\n",
      "[0, 2, 3, 7]\n",
      "[0, 1, 3, 4, 5, 6, 7]\n",
      "[0, 2, 3, 4, 5, 7]\n",
      "[0, 2, 4, 6, 7]\n",
      "[0, 1, 2, 3, 5, 7]\n",
      "[0, 1, 2, 3, 5, 6]\n",
      "[0, 3, 4, 6]\n",
      "[0, 1, 2, 3, 5, 7]\n",
      "[0, 1, 2, 4, 5, 6, 7]\n",
      "[0, 2, 3, 6, 7]\n",
      "[0, 1, 2, 3, 4, 7]\n",
      "[0, 3, 4, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "x = [50258, 50259, 50263, 50260, 50261, 50264, 50265, 50262]\n",
    "for i_batch, sample_batched in enumerate(dataloader):    \n",
    "    cond = sample_batched[0][0]\n",
    "    cond_set = cond.split(',')\n",
    "    condition_string = ''\n",
    "    \n",
    "    for m in range(len(cond_set)):\n",
    "        cond_set[m] = cond_set[m].strip()\n",
    "        pos = cond_set[m].index('[')\n",
    "\n",
    "        condition_string += '<' + cond_set[m][:pos] + '> '\n",
    "    \n",
    "    con_list = my_model.tokenizer.encode(condition_string.strip())\n",
    "    \n",
    "    out = []\n",
    "    for k in range(len(con_list)):\n",
    "        out.append(x.index(con_list[k]))\n",
    "    print(out)\n",
    "    assert out == sorted(out)\n",
    "    if i_batch == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 6, 3, 4, 5], [1, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, sorted(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=[1,6,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Half dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class e2eDataset(Dataset):\n",
    "    def __init__(self, csv_file1, csv_file2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): csv 파일의 경로\n",
    "        \"\"\"\n",
    "        self.dataset1 = pd.read_csv(csv_file1)\n",
    "        self.dataset2 = pd.read_csv(csv_file2)\n",
    "        \n",
    "        self.columns1 = self.dataset1.columns\n",
    "        self.columns2 = self.dataset2.columns\n",
    "        \n",
    "        self.conditions = list(self.dataset1[self.columns1[0]]) + list(self.dataset2[self.columns2[0]])\n",
    "        self.sentences = list(self.dataset1[self.columns1[1]]) + list(self.dataset2[self.columns2[1]])\n",
    "        \n",
    "        self.typ_list = {}\n",
    "        for k in range(len(self.conditions)):\n",
    "            cond_set = self.conditions[k].split(',')\n",
    "            for m in range(len(cond_set)):\n",
    "                cond_set[m] = cond_set[m].strip()\n",
    "                pos = cond_set[m].index('[')\n",
    "                if cond_set[m][:pos] in self.typ_list.keys():\n",
    "                    self.typ_list[cond_set[m][:pos]].add(cond_set[m][pos+1:-1])\n",
    "                else:            \n",
    "                    self.typ_list[cond_set[m][:pos]] = {cond_set[m][pos+1:-1]}\n",
    "                    \n",
    "        k = 0\n",
    "        sample_order = []\n",
    "        for _ in range(len(self.conditions)):\n",
    "            sample_order.append(k)\n",
    "            k += 1\n",
    "        ran_num = random.sample(sample_order, int(len(self.conditions)/2))\n",
    "        self.conditions_sample = [self.conditions[t] for t in ran_num]\n",
    "        self.sentences_sample = [self.sentences[t] for t in ran_num]                  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.conditions_sample)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cond = self.conditions_sample[idx]\n",
    "        cond_set = cond.split(',')\n",
    "        condition_string = ''\n",
    "        for m in range(len(cond_set)):\n",
    "            cond_set[m] = cond_set[m].strip()\n",
    "            pos = cond_set[m].index('[')\n",
    "            \n",
    "            condition_string += '<' + cond_set[m][:pos] + '>' + cond_set[m][pos+1:-1] + ' '\n",
    "        \n",
    "        sen = self.sentences_sample[idx]\n",
    "\n",
    "        return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_dataset = e2eDataset(csv_file1='dataset/trainset.csv', csv_file2='dataset/devset.csv')\n",
    "dataloader = DataLoader(e2e_dataset, batch_size=1, shuffle=True, num_workers=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46733, 23366, 23366)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e2e_dataset.conditions), len(e2e_dataset.conditions_sample), len(e2e_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "x1 = [11,22,33,44,55,66]\n",
    "x2 = [111,222,333,444,555,666]\n",
    "k = 0\n",
    "li = []\n",
    "for _ in range(len(x1)):\n",
    "    li.append(k)\n",
    "    k += 1\n",
    "ran_num = random.sample(li, int(len(x1)/2))\n",
    "sample_x1 = [x1[t] for t in ran_num]\n",
    "sample_x2 = [x2[t] for t in ran_num]\n",
    "sample_x1, sample_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15221699281644785\n",
      "0.474525094505599\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "# csv_file=\"/data/private/E2E/dataset/testset_w_refs.csv\"\n",
    "csv_file=\"/data/private/E2E/dataset/trainset.csv\"\n",
    "dataset = pd.read_csv(csv_file)\n",
    "columns = dataset.columns\n",
    "conditions = dataset[columns[0]]\n",
    "refs = dataset[columns[1]]\n",
    "\n",
    "incomplte_num = 0\n",
    "total_value_num = 0\n",
    "not_include_count  = 0\n",
    "for ind in range(len(conditions)):\n",
    "    cond_dict = {}\n",
    "    cond_set = conditions[ind].split(',')\n",
    "    \n",
    "    for m in range(len(cond_set)):\n",
    "        cond_set[m] = cond_set[m].strip()\n",
    "        pos = cond_set[m].index('[')\n",
    "        cond_dict[cond_set[m][:pos]] = (cond_set[m][pos+1:-1])    \n",
    "        \n",
    "    num = len(cond_dict)\n",
    "    total_value_num += num\n",
    "    \n",
    "    sentence_temp = refs[ind]\n",
    "    \n",
    "    for k, v in cond_dict.items():\n",
    "        if k != 'familyFriendly':\n",
    "            if v.lower() not in sentence_temp.strip().lower():\n",
    "                not_include_count += 1\n",
    "            \n",
    "    for k, v in cond_dict.items():\n",
    "        if k != 'familyFriendly':\n",
    "            if v.lower() not in sentence_temp.strip().lower():\n",
    "                incomplte_num += 1\n",
    "                break\n",
    "                \n",
    "print(not_include_count/total_value_num)\n",
    "print(incomplte_num/len(conditions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32332"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "0.15221699281644785\n",
    "0.474525094505599\n",
    "\n",
    "# test\n",
    "0.11579858963256216\n",
    "0.4528020455998295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
