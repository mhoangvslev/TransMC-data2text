{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class e2eDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): csv 파일의 경로\n",
    "        \"\"\"\n",
    "        self.dataset = pd.read_csv(csv_file)\n",
    "        self.columns = self.dataset.columns\n",
    "        self.conditions = self.dataset[self.columns[0]]\n",
    "        self.sentences = self.dataset[self.columns[1]]\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.typ_list = {}\n",
    "        for k in range(len(self.conditions)):\n",
    "            cond_set = self.conditions[k].split(',')\n",
    "            for m in range(len(cond_set)):\n",
    "                cond_set[m] = cond_set[m].strip()\n",
    "                pos = cond_set[m].index('[')\n",
    "                if cond_set[m][:pos] in self.typ_list.keys():\n",
    "                    self.typ_list[cond_set[m][:pos]].add(cond_set[m][pos+1:-1])\n",
    "                else:            \n",
    "                    self.typ_list[cond_set[m][:pos]] = {cond_set[m][pos+1:-1]}        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.conditions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cond = self.conditions[idx]\n",
    "        cond_set = cond.split(',')\n",
    "        condition_string = ''\n",
    "        for m in range(len(cond_set)):\n",
    "            cond_set[m] = cond_set[m].strip()\n",
    "            pos = cond_set[m].index('[')\n",
    "            \n",
    "            condition_string += '<' + cond_set[m][:pos] + '>' + cond_set[m][pos+1:-1] + ' '\n",
    "        \n",
    "        sen = self.sentences[idx]\n",
    "        input_string = condition_string + '<START>'\n",
    "        input_ids = torch.tensor(self.tokenizer.encode(input_string, add_special_tokens=True))\n",
    "        \n",
    "        input_len = len(input_ids)\n",
    "\n",
    "        return input_ids, sen, condition_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0423 02:37:42.599551 140472973551424 tokenization_utils.py:504] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/ds_user1/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "I0423 02:37:42.600461 140472973551424 tokenization_utils.py:504] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/ds_user1/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0423 02:37:42.677000 140472973551424 tokenization_utils.py:663] Adding <START> to the vocabulary\n",
      "I0423 02:37:42.677967 140472973551424 tokenization_utils.py:741] Assigning <START> to the bos_token key of the tokenizer\n",
      "I0423 02:37:42.678765 140472973551424 tokenization_utils.py:663] Adding <name> to the vocabulary\n",
      "I0423 02:37:42.679470 140472973551424 tokenization_utils.py:663] Adding <eatType> to the vocabulary\n",
      "I0423 02:37:42.680124 140472973551424 tokenization_utils.py:663] Adding <priceRange> to the vocabulary\n",
      "I0423 02:37:42.680822 140472973551424 tokenization_utils.py:663] Adding <customer rating> to the vocabulary\n",
      "I0423 02:37:42.681425 140472973551424 tokenization_utils.py:663] Adding <near> to the vocabulary\n",
      "I0423 02:37:42.682073 140472973551424 tokenization_utils.py:663] Adding <food> to the vocabulary\n",
      "I0423 02:37:42.682697 140472973551424 tokenization_utils.py:663] Adding <area> to the vocabulary\n",
      "I0423 02:37:42.683324 140472973551424 tokenization_utils.py:663] Adding <familyFriendly> to the vocabulary\n",
      "I0423 02:37:42.684026 140472973551424 tokenization_utils.py:741] Assigning ['<name>', '<eatType>', '<priceRange>', '<customer rating>', '<near>', '<food>', '<area>', '<familyFriendly>'] to the additional_special_tokens key of the tokenizer\n",
      "I0423 02:37:43.487324 140472973551424 configuration_utils.py:275] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/ds_user1/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
      "I0423 02:37:43.488402 140472973551424 configuration_utils.py:311] Model config GPT2Config {\n",
      "  \"_num_labels\": 2,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "I0423 02:37:44.270570 140472973551424 modeling_utils.py:503] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /home/ds_user1/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "my_model = mymodel().cuda()\n",
    "my_model.eval()\n",
    "my_model.load_state_dict(torch.load('./gen_model/base/2/model'))\n",
    "print('ok') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e2e_dataset = e2eDataset(csv_file='dataset/testset_w_refs.csv', tokenizer=my_model.tokenizer)\n",
    "# e2e_dataset = e2eDataset(csv_file='dataset/trainset.csv', tokenizer=my_model.tokenizer)\n",
    "e2e_dataset = e2eDataset(csv_file='dataset/devset.csv', tokenizer=my_model.tokenizer)\n",
    "dataloader = DataLoader(e2e_dataset, batch_size=1, shuffle=False, num_workers=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50258, 50259, 50263, 50260, 50261, 50264, 50265, 50262]\n",
      "['<name>', '<|endoftext|>', '<area>', '<near>', '<START>', '<customer rating>', '<familyFriendly>', '<food>', '<eatType>', '<priceRange>']\n",
      "<name>\n",
      "<eatType>\n",
      "<food>\n",
      "<priceRange>\n",
      "<customer rating>\n",
      "<area>\n",
      "<familyFriendly>\n",
      "<near>\n"
     ]
    }
   ],
   "source": [
    "# x = my_model.tokenizer.additional_special_tokens_ids\n",
    "x = [50258, 50259, 50263, 50260, 50261, 50264, 50265, 50262]\n",
    "print(x)\n",
    "print(my_model.tokenizer.all_special_tokens)\n",
    "for i in range(len(x)):\n",
    "    print(my_model.tokenizer.decode([x[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4672it [00:03, 1311.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "same_condition = []\n",
    "ref_sentences = []\n",
    "input_ids_list = []\n",
    "pre_condition_string = ''\n",
    "start = 0\n",
    "for i_batch, sample_batched in tqdm(enumerate(dataloader)):\n",
    "    sen = sample_batched[1][0]\n",
    "#     print(i_batch, sen)\n",
    "    condition_string = sample_batched[2]  \n",
    "    input_ids = sample_batched[0].squeeze(0).cuda()\n",
    "        \n",
    "    if start == 0 or condition_string == pre_condition_string:      \n",
    "        if start == 0:\n",
    "            input_ids_list.append(input_ids)\n",
    "        same_condition.append(sen)        \n",
    "        pre_condition_string = condition_string\n",
    "        start += 1\n",
    "    else:   \n",
    "        input_ids_list.append(input_ids)\n",
    "        ref_sentences.append(same_condition)\n",
    "        pre_condition_string = condition_string\n",
    "        same_condition = [sen]\n",
    "        start += 1\n",
    "\n",
    "#     if i_batch == 30:\n",
    "#         break            \n",
    "ref_sentences.append(same_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(547, 547)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ref_sentences), len(input_ids_list)\n",
    "# input_ids_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ds_user1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 73.41162457057993\n",
      "BLEU1 score: 89.30558590312106\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "max_len = 50\n",
    "start_time = time.time()\n",
    "bleu_score = 0\n",
    "bleu_1 = 0\n",
    "\n",
    "f_dev = open('./predictions/base/f_dev_2.txt', 'w')\n",
    "f_pred = open('./predictions/base/f_pred_2.txt', 'w')\n",
    "\n",
    "for k in range(len(ref_sentences)):\n",
    "    input_ids = input_ids_list[k]\n",
    "    input_len = len(input_ids)\n",
    "\n",
    "    ori_tokens = []\n",
    "    for m in range(len(ref_sentences[k])):\n",
    "        f_dev.write(ref_sentences[k][m]+'\\n')\n",
    "        ori_tokens.append(word_tokenize(ref_sentences[k][m]))\n",
    "    if k < len(ref_sentences)-1:\n",
    "        f_dev.write('\\n')\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        model_out = my_model.model_feeding(input_ids) # (batch, seq_len, emb_dim)\n",
    "        pred_idx = model_out.argmax(1)[-1]        \n",
    "        if pred_idx == my_model.tokenizer.eos_token_id:\n",
    "            break            \n",
    "        input_ids = torch.cat((input_ids, pred_idx.unsqueeze(0)), 0)        \n",
    "    \n",
    "    out_sen = my_model.tokenizer.decode(input_ids[input_len:])\n",
    "    f_pred.write(out_sen+'\\n')\n",
    "    \n",
    "#     print(ref_sentences[k])\n",
    "#     print(out_sen)    \n",
    "    \n",
    "    out_tokens = word_tokenize(out_sen)\n",
    "    \n",
    "    bleu_1_score = sentence_bleu(ori_tokens, out_tokens, weights=(1, 0, 0, 0))\n",
    "    bleu_2_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.5, 0.5, 0, 0))\n",
    "    bleu_3_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.33, 0.33, 0.33, 0))\n",
    "    bleu_4_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    \n",
    "    bleu_1 += bleu_1_score\n",
    "\n",
    "    bleu_score += min(1, len(out_tokens)/len(ori_tokens))*((bleu_1_score*bleu_2_score*bleu_3_score*bleu_4_score)**(0.25))    \n",
    "    \n",
    "#     print(\"time: {}\".format(time.time()-start_time))\n",
    "#     print('')\n",
    "f_dev.close()\n",
    "f_pred.close()\n",
    "    \n",
    "print(\"BLEU score: {}\".format(bleu_score/len(ref_sentences)*100))\n",
    "print(\"BLEU1 score: {}\".format(bleu_1/len(ref_sentences)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLEU score: 71.18825887456514\n",
    "BLEU1 score: 88.76109911863252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "./measure_scores.py ../predictions/base/f_dev_6.txt ../predictions/base/f_pred_6.txt\n",
    "./measure_scores.py ../predictions/base2/f_dev_2.txt ../predictions/base2/f_pred_2.txt\n",
    "./measure_scores.py ../predictions/large/f_dev_5.txt ../predictions/large/f_pred_5.txt\n",
    "./measure_scores.py ../predictions/f_dev_2.txt ../predictions/large2/f_pred_2.txt\n",
    "\n",
    "### Large\n",
    "#### my_output_1\n",
    "BLEU: 0.6826\n",
    "NIST: 8.4243\n",
    "METEOR: 0.4557\n",
    "ROUGE_L: 0.7032\n",
    "CIDEr: 2.1234\n",
    "\n",
    "#### my_output_2\n",
    "BLEU: 0.7228\n",
    "NIST: 8.5241\n",
    "METEOR: 0.4851\n",
    "ROUGE_L: 0.7461\n",
    "CIDEr: 2.4645\n",
    "\n",
    "#### my_output_3\n",
    "BLEU: 0.7035\n",
    "NIST: 8.5937\n",
    "METEOR: 0.4700\n",
    "ROUGE_L: 0.7252\n",
    "CIDEr: 2.3310\n",
    "\n",
    "#### my_output_4\n",
    "BLEU: 0.6738\n",
    "NIST: 8.4018\n",
    "METEOR: 0.4576\n",
    "ROUGE_L: 0.7075\n",
    "CIDEr: 2.2172\n",
    "\n",
    "#### my_output_5\n",
    "BLEU: 0.6927\n",
    "NIST: 8.4429\n",
    "METEOR: 0.4662\n",
    "ROUGE_L: 0.7180\n",
    "CIDEr: 2.2729\n",
    "\n",
    "### base\n",
    "#### my_output_2\n",
    "BLEU: 0.6812\n",
    "NIST: 8.5491\n",
    "METEOR: 0.4442\n",
    "ROUGE_L: 0.7036\n",
    "CIDEr: 2.1261\n",
    "\n",
    "#### my_output_6\n",
    "BLEU: 0.6655\n",
    "NIST: 8.4830\n",
    "METEOR: 0.4475\n",
    "ROUGE_L: 0.6992\n",
    "CIDEr: 2.1077\n",
    "    \n",
    "#### my_output_final\n",
    "BLEU: 0.6529\n",
    "NIST: 8.3116\n",
    "METEOR: 0.4430\n",
    "ROUGE_L: 0.6842\n",
    "CIDEr: 1.9766\n",
    "\n",
    "### Pragmatically Informative Text Generation\n",
    "BLEU 68.60\n",
    "NIST 8.73\n",
    "METEOR 45.25\n",
    "R-L 70.82\n",
    "CIDEr 2.37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model_large import *\n",
    "from model import *\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "max_len = 70\n",
    "\n",
    "my_model = mymodel().cuda()\n",
    "my_model.eval()\n",
    "\n",
    "for i in range(1, 9):\n",
    "    model_name = './gen_model/base_devtrain_5/'+str(i)+'/model'\n",
    "    my_model.load_state_dict(torch.load(model_name))\n",
    "    print('ok') \n",
    "    if i == 1:\n",
    "#         e2e_dataset = e2eDataset(csv_file='dataset/devset.csv', tokenizer=my_model.tokenizer)\n",
    "        e2e_dataset = e2eDataset(csv_file='dataset/testset_w_refs.csv', tokenizer=my_model.tokenizer)\n",
    "        dataloader = DataLoader(e2e_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "        same_condition = []\n",
    "        ref_sentences = []\n",
    "        input_ids_list = []\n",
    "        pre_condition_string = ''\n",
    "        start = 0\n",
    "        for i_batch, sample_batched in tqdm(enumerate(dataloader)):\n",
    "            sen = sample_batched[1][0]\n",
    "            condition_string = sample_batched[2]  \n",
    "            input_ids = sample_batched[0].squeeze(0).cuda()\n",
    "\n",
    "            if start == 0 or condition_string == pre_condition_string:      \n",
    "                if start == 0:\n",
    "                    input_ids_list.append(input_ids)\n",
    "                same_condition.append(sen)        \n",
    "                pre_condition_string = condition_string\n",
    "                start += 1\n",
    "            else:   \n",
    "                input_ids_list.append(input_ids)\n",
    "                ref_sentences.append(same_condition)\n",
    "                pre_condition_string = condition_string\n",
    "                same_condition = [sen]\n",
    "                start += 1\n",
    "        ref_sentences.append(same_condition)    \n",
    "\n",
    "    bleu_score = 0\n",
    "    bleu_1 = 0\n",
    "\n",
    "#     f_dev = open('./predictions/testset/large2/f_dev_'+str(i)+'.txt', 'w')\n",
    "#     f_pred = open('./predictions/devset/base4/f_pred_'+str(i)+'.txt', 'w')\n",
    "    f_pred = open('./predictions/testset/base5_dev/f_pred_'+str(i)+'.txt', 'w')\n",
    "\n",
    "    for k in range(len(ref_sentences)):\n",
    "        input_ids = input_ids_list[k]\n",
    "        input_len = len(input_ids)\n",
    "\n",
    "        ori_tokens = []\n",
    "        for m in range(len(ref_sentences[k])):\n",
    "#             f_dev.write(ref_sentences[k][m]+'\\n')\n",
    "            ori_tokens.append(word_tokenize(ref_sentences[k][m]))\n",
    "#         if k < len(ref_sentences)-1:\n",
    "#             f_dev.write('\\n')\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            model_out = my_model.model_feeding(input_ids) # (batch, seq_len, emb_dim)\n",
    "            pred_idx = model_out.argmax(1)[-1]        \n",
    "            if pred_idx == my_model.tokenizer.eos_token_id:\n",
    "                break            \n",
    "            input_ids = torch.cat((input_ids, pred_idx.unsqueeze(0)), 0)        \n",
    "\n",
    "        out_sen = my_model.tokenizer.decode(input_ids[input_len:])\n",
    "        f_pred.write(out_sen+'\\n')\n",
    "\n",
    "        out_tokens = word_tokenize(out_sen)\n",
    "\n",
    "        bleu_1_score = sentence_bleu(ori_tokens, out_tokens, weights=(1, 0, 0, 0))\n",
    "        bleu_2_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.5, 0.5, 0, 0))\n",
    "        bleu_3_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.33, 0.33, 0.33, 0))\n",
    "        bleu_4_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "        bleu_1 += bleu_1_score\n",
    "\n",
    "        bleu_score += min(1, len(out_tokens)/len(ori_tokens))*((bleu_1_score*bleu_2_score*bleu_3_score*bleu_4_score)**(0.25))    \n",
    "\n",
    "#     f_dev.close()\n",
    "    f_pred.close()\n",
    "    \n",
    "    print(i, \"th model\")\n",
    "    print(\"BLEU score: {}\".format(bleu_score/len(ref_sentences)*100))\n",
    "    print(\"BLEU1 score: {}\".format(bleu_1/len(ref_sentences)*100))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BERT score with human reference\n",
    "from bert_score import score\n",
    "import glob\n",
    "human_files = \"/project/work/E2E/predictions/testset/f_dev.txt\"\n",
    "\n",
    "human_open = open(human_files, \"r\")\n",
    "human_dataset = human_open.readlines()\n",
    "human_open.close()\n",
    "\n",
    "human_references = []\n",
    "\n",
    "temp_reference = []\n",
    "for i in range(len(human_dataset)):\n",
    "    if human_dataset[i] == '\\n':\n",
    "        human_references.append(temp_reference)\n",
    "        temp_reference = []\n",
    "    else:\n",
    "        temp_reference.append(human_dataset[i].strip())\n",
    "human_references.append(temp_reference)\n",
    "human_compare = []\n",
    "for i in range(len(human_references)):\n",
    "    for k in range(len(human_references[i])):\n",
    "        human_compare.append(human_references[i][k])\n",
    "\n",
    "output_path = \"/project/work/E2E/predictions/testset/base2_sample10/*\"\n",
    "pred_files = glob.glob(output_path)\n",
    "\n",
    "score_list = []\n",
    "for i in range(len(pred_files)):    \n",
    "    cands = []\n",
    "    pred_data_open = open(pred_files[i], \"r\")\n",
    "    pred_data_dataset = pred_data_open.readlines()\n",
    "    pred_len = len(pred_data_dataset)\n",
    "    pred_data_open.close()\n",
    "    \n",
    "    for k in range(len(pred_data_dataset)):\n",
    "        out_sen = pred_data_dataset[k].strip()\n",
    "        repeat_num = len(human_references[k])\n",
    "        for _ in range(repeat_num):\n",
    "            cands.append(out_sen)\n",
    "\n",
    "    P, R, F1 = score(cands, human_compare, lang='en', verbose=True)\n",
    "    F1_list=list(F1.numpy())\n",
    "    BERT_score = sum(F1_list)/len(F1_list)\n",
    "    \n",
    "    score_list.append(BERT_score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/project/work/E2E/predictions/testset/base2_sample10/f_pred_3.txt',\n",
       "  '/project/work/E2E/predictions/testset/base2_sample10/f_pred_7.txt',\n",
       "  '/project/work/E2E/predictions/testset/base2_sample10/f_pred_5.txt',\n",
       "  '/project/work/E2E/predictions/testset/base2_sample10/f_pred_9.txt',\n",
       "  '/project/work/E2E/predictions/testset/base2_sample10/f_pred_1.txt',\n",
       "  '/project/work/E2E/predictions/testset/base2_sample10/f_pred_10.txt',\n",
       "  '/project/work/E2E/predictions/testset/base2_sample10/f_pred_4.txt',\n",
       "  '/project/work/E2E/predictions/testset/base2_sample10/f_pred_8.txt',\n",
       "  '/project/work/E2E/predictions/testset/base2_sample10/f_pred_6.txt',\n",
       "  '/project/work/E2E/predictions/testset/base2_sample10/f_pred_2.txt'],\n",
       " [0.9340897221415886,\n",
       "  0.9375306307291542,\n",
       "  0.9385130896945256,\n",
       "  0.9396600867420175,\n",
       "  0.896774981541596,\n",
       "  0.9385862989438868,\n",
       "  0.9347218730773291,\n",
       "  0.9386929859872213,\n",
       "  0.9381917336336107,\n",
       "  0.9325849555993218])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_files, score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BERT score with human reference\n",
    "import csv\n",
    "from bert_score import score\n",
    "import glob\n",
    "human_files = \"/project/work/E2E/predictions/testset/f_dev.txt\"\n",
    "\n",
    "human_open = open(human_files, \"r\")\n",
    "human_dataset = human_open.readlines()\n",
    "human_open.close()\n",
    "\n",
    "human_references = []\n",
    "\n",
    "temp_reference = []\n",
    "for i in range(len(human_dataset)):\n",
    "    if human_dataset[i] == '\\n':\n",
    "        human_references.append(temp_reference)\n",
    "        temp_reference = []\n",
    "    else:\n",
    "        temp_reference.append(human_dataset[i].strip())\n",
    "human_references.append(temp_reference)\n",
    "human_compare = []\n",
    "for i in range(len(human_references)):\n",
    "    for k in range(len(human_references[i])):\n",
    "        human_compare.append(human_references[i][k])\n",
    "\n",
    "output_path = \"/project/work/E2E/compared_system/system_outputs/primary_txt/*\"\n",
    "pred_files = glob.glob(output_path)\n",
    "\n",
    "score_list = []\n",
    "for i in range(len(pred_files)):    \n",
    "    cands = []\n",
    "    pred_data_open = open(pred_files[i], \"r\")\n",
    "    pred_data_dataset = pred_data_open.readlines()\n",
    "    pred_len = len(pred_data_dataset)\n",
    "    pred_data_open.close()\n",
    "    \n",
    "    for k in range(len(pred_data_dataset)):\n",
    "        out_sen = pred_data_dataset[k].strip()\n",
    "        repeat_num = len(human_references[k])\n",
    "        for _ in range(repeat_num):\n",
    "            cands.append(out_sen)\n",
    "\n",
    "    P, R, F1 = score(cands, human_compare, lang='en', verbose=True)\n",
    "    F1_list=list(F1.numpy())\n",
    "    BERT_score = sum(F1_list)/len(F1_list)\n",
    "    \n",
    "    score_list.append(BERT_score)  \n",
    "print(pred_files, score_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/work/E2E/compared_system/system_outputs/primary_txt/adapt.txt 0.9224714525544057\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/forge3.txt 0.9277185035519018\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/tgen.txt 0.9391622960808789\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/chen.txt 0.9121247716430608\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/sheff2.txt 0.9337284921863148\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/tuda.txt 0.9388613972027826\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/forge1.txt 0.9296145912378093\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/dangnt.txt 0.9390964954615199\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/zhaw2.txt 0.9328836475052662\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/zhang.txt 0.931265755944889\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/tr2.txt 0.927562745489242\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/tnt2.txt 0.9302622135351544\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/slug.txt 0.9424661084606326\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/gong.txt 0.9403216674742911\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/zhaw1.txt 0.9322725058160762\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/tr1.txt 0.9140929393287714\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/tnt1.txt 0.9303506949982764\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/nle.txt 0.9395513920775868\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/sheff1.txt 0.938225149765417\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/slug-alt.txt 0.9345733890039641\n",
      "/project/work/E2E/compared_system/system_outputs/primary_txt/harv.txt 0.9390245682645042\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred_files)):\n",
    "    print(pred_files[i], score_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./predictions/joosung2/testset/f_dev.txt /project/work/E2E/compared_system/system_outputs/primary_txt/adapt.txt None\n",
      "Running MS-COCO evaluator...\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 129948 tokens at 550313.49 tokens per second.\n",
      "PTBTokenizer tokenized 18044 tokens at 185180.01 tokens per second.\n",
      "setting up scorers...\n",
      "computing METEOR score...\n",
      "METEOR: 0.402\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.587\n",
      "computing CIDEr score...\n",
      "CIDEr: 1.504\n",
      "Creating temp directory  /tmp/e2e-eval-5ml836vl\n",
      "Running MTEval to compute BLEU & NIST...\n"
     ]
    }
   ],
   "source": [
    "# !./e2e-metrics/measure_scores.py ./predictions/testset/f_dev.txt ./predictions/testset/base5_dev/f_pred_1.txt\n",
    "# !./e2e-metrics/measure_scores.py ./predictions/testset/f_dev.txt ./predictions/testset/base5_dev/f_pred_2.txt\n",
    "# !./e2e-metrics/measure_scores.py ./predictions/testset/f_dev.txt ./predictions/testset/base5_dev/f_pred_3.txt\n",
    "# !./e2e-metrics/measure_scores.py ./predictions/testset/f_dev.txt ./predictions/testset/base5_dev/f_pred_4.txt\n",
    "# !./e2e-metrics/measure_scores.py ./predictions/testset/f_dev.txt ./predictions/testset/base5_dev/f_pred_5.txt\n",
    "# !./e2e-metrics/measure_scores.py ./predictions/testset/f_dev.txt ./predictions/testset/base5_dev/f_pred_6.txt\n",
    "# !./e2e-metrics/measure_scores.py ./predictions/testset/f_dev.txt ./predictions/testset/base5_dev/f_pred_7.txt\n",
    "# !./e2e-metrics/measure_scores.py ./predictions/testset/f_dev.txt ./predictions/testset/base5_dev/f_pred_8.txt\n",
    "# !./e2e-metrics/measure_scores.py ./predictions/joosung2/testset/f_dev.txt ./predictions/final/1base1_sample10_6.txt\n",
    "# !./e2e-metrics/measure_scores.py ./predictions/joosung2/testset/f_dev.txt ./predictions/final/1base2_sample10_9.txt\n",
    "# !./e2e-metrics/measure_scores.py ./predictions/joosung2/testset/f_dev.txt ./predictions/final/1base4_devtest_4.txt\n",
    "# !./e2e-metrics/measure_scores.py ./predictions/joosung2/testset/f_dev.txt ./predictions/final/2base1_sample50_7.txt\n",
    "!./e2e-metrics/measure_scores.py ./predictions/joosung2/testset/f_dev.txt /project/work/E2E/compared_system/system_outputs/primary_txt/harv.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tsv to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "output_path = \"/project/work/E2E/compared_system/system_outputs/primary/*\"\n",
    "comapred_files = glob.glob(output_path)\n",
    "\n",
    "for i in range(len(comapred_files)):\n",
    "    dataset = pd.read_csv(comapred_files[i], delimiter='\\t', header=None)\n",
    "    \n",
    "    name = comapred_files[i].split('/')[-1].split('.')[0]\n",
    "    txt_files = \"/project/work/E2E/compared_system/system_outputs/primary_txt/\"+name+\".txt\"\n",
    "    f = open(txt_files, \"w\")\n",
    "    gen_sentences = dataset[1]\n",
    "    \n",
    "    for k in range(1, len(gen_sentences)):\n",
    "        f.write(gen_sentences[k]+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gen_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zero-shot test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0426 01:41:04.955722 140426112489280 file_utils.py:41] PyTorch version 1.2.0 available.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "I0426 01:41:08.670083 140426112489280 tokenization_utils.py:504] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/ds_user1/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "I0426 01:41:08.670933 140426112489280 tokenization_utils.py:504] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/ds_user1/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0426 01:41:08.740889 140426112489280 tokenization_utils.py:663] Adding <START> to the vocabulary\n",
      "I0426 01:41:08.742121 140426112489280 tokenization_utils.py:741] Assigning <START> to the bos_token key of the tokenizer\n",
      "I0426 01:41:08.742609 140426112489280 tokenization_utils.py:663] Adding <name> to the vocabulary\n",
      "I0426 01:41:08.743112 140426112489280 tokenization_utils.py:663] Adding <eatType> to the vocabulary\n",
      "I0426 01:41:08.743579 140426112489280 tokenization_utils.py:663] Adding <priceRange> to the vocabulary\n",
      "I0426 01:41:08.744043 140426112489280 tokenization_utils.py:663] Adding <customer rating> to the vocabulary\n",
      "I0426 01:41:08.744530 140426112489280 tokenization_utils.py:663] Adding <near> to the vocabulary\n",
      "I0426 01:41:08.744998 140426112489280 tokenization_utils.py:663] Adding <food> to the vocabulary\n",
      "I0426 01:41:08.745454 140426112489280 tokenization_utils.py:663] Adding <area> to the vocabulary\n",
      "I0426 01:41:08.745902 140426112489280 tokenization_utils.py:663] Adding <familyFriendly> to the vocabulary\n",
      "I0426 01:41:08.746386 140426112489280 tokenization_utils.py:741] Assigning ['<name>', '<eatType>', '<priceRange>', '<customer rating>', '<near>', '<food>', '<area>', '<familyFriendly>'] to the additional_special_tokens key of the tokenizer\n",
      "I0426 01:41:09.540093 140426112489280 filelock.py:274] Lock 140426033563408 acquired on /home/ds_user1/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5.lock\n",
      "I0426 01:41:09.541612 140426112489280 file_utils.py:479] https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json not found in cache or force_download set to True, downloading to /home/ds_user1/.cache/torch/transformers/tmpc6ou5i0y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a69344d24564a7288ec4a2a5fa58a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=554.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0426 01:41:10.361212 140426112489280 file_utils.py:489] storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json in cache at /home/ds_user1/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n",
      "I0426 01:41:10.362656 140426112489280 file_utils.py:492] creating metadata file for /home/ds_user1/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n",
      "I0426 01:41:10.363654 140426112489280 filelock.py:318] Lock 140426033563408 released on /home/ds_user1/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5.lock\n",
      "I0426 01:41:10.364660 140426112489280 configuration_utils.py:275] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/ds_user1/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n",
      "I0426 01:41:10.365779 140426112489280 configuration_utils.py:311] Model config GPT2Config {\n",
      "  \"_num_labels\": 2,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0426 01:41:11.145596 140426112489280 modeling_utils.py:503] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /home/ds_user1/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import *\n",
    "\n",
    "max_len = 70\n",
    "my_model = mymodel().cuda()\n",
    "my_model.eval()\n",
    "model_name = './gen_model/base_devtrain_4/4/model'\n",
    "my_model.load_state_dict(torch.load(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<name>', '<eatType>', '<area>', '<familyFriendly>', '<near>']\n",
      "['Blue Spice', 'pub', 'city centre', 'no', 'Rainbow Vegetarian Café']\n",
      "Blue Spice is a pub located in the city centre near Rainbow Vegetarian Café. It is not family-friendly.\n",
      "<NAME> is a <EATTYPE> located in the <AREA> near <NEAR>. It is not family-friendly.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "csv_file='dataset/testset_w_refs.csv'\n",
    "dataset = pd.read_csv(csv_file)\n",
    "columns = dataset.columns\n",
    "conditions = dataset[columns[0]]\n",
    "        \n",
    "typ_list = {}\n",
    "for k in range(len(conditions)):\n",
    "    cond_set = conditions[k].split(',')\n",
    "    for m in range(len(cond_set)):\n",
    "        cond_set[m] = cond_set[m].strip()\n",
    "        pos = cond_set[m].index('[')\n",
    "        if cond_set[m][:pos] in typ_list.keys():\n",
    "            typ_list[cond_set[m][:pos]].add(cond_set[m][pos+1:-1])\n",
    "        else:            \n",
    "            typ_list[cond_set[m][:pos]] = {cond_set[m][pos+1:-1]}   \n",
    "\n",
    "def sample_batch(tokenizer, cond_name, cond_set):\n",
    "    condition_string = ''\n",
    "    for m in range(len(cond_set)):\n",
    "        condition_string += cond_name[m] + cond_set[m] + ' '\n",
    "\n",
    "    input_string = condition_string + '<START>'\n",
    "    input_ids = torch.tensor(tokenizer.encode(input_string, add_special_tokens=True))\n",
    "\n",
    "    input_len = len(input_ids)\n",
    "\n",
    "    return input_ids, condition_string\n",
    "\n",
    "# <name> <eatType> <food> <priceRange> <customer rating> <area> <familyFriendly> <near>\n",
    "\n",
    "name = '<NAME>'\n",
    "eatType = '<EATTYPE>' # '<EATTYPE>'\n",
    "food = None # '<FOOD>'\n",
    "priceRange = None\n",
    "customer_rating = None #'<CUSTOMER_RATING>'\n",
    "area = '<AREA>'\n",
    "familyFriendly = 'no'\n",
    "near = '<NEAR>' # None\n",
    "\n",
    "cond_list = []\n",
    "conditions = []\n",
    "if name is not None:\n",
    "    placeholder_name = random.choice(list(typ_list['name']))\n",
    "    cond_list.append('<name>')\n",
    "    conditions.append(placeholder_name)\n",
    "if eatType is not None:\n",
    "    placeholder_eatType = random.choice(list(typ_list['eatType']))\n",
    "    cond_list.append('<eatType>')\n",
    "    conditions.append(placeholder_eatType)\n",
    "if food is not None:\n",
    "    placeholder_food = random.choice(list(typ_list['food']))\n",
    "    cond_list.append('<food>')\n",
    "    conditions.append(placeholder_food)\n",
    "if priceRange is not None:\n",
    "    placeholder_priceRange = random.choice(list(typ_list['priceRange']))\n",
    "    cond_list.append('<priceRange>')\n",
    "    conditions.append(placeholder_priceRange)    \n",
    "if customer_rating is not None:\n",
    "    placeholder_customer_rating = random.choice(list(typ_list['customer rating']))\n",
    "    cond_list.append('<customer rating>')\n",
    "    conditions.append(placeholder_customer_rating)        \n",
    "if area is not None:\n",
    "    placeholder_area = random.choice(list(typ_list['area']))\n",
    "    cond_list.append('<area>')\n",
    "    conditions.append(placeholder_area)    \n",
    "if familyFriendly is not None:\n",
    "    cond_list.append('<familyFriendly>')\n",
    "    conditions.append(familyFriendly)            \n",
    "if near is not None:\n",
    "    placeholder_near = random.choice(list(typ_list['near']))\n",
    "    cond_list.append('<near>')\n",
    "    conditions.append(placeholder_near)        \n",
    "\n",
    "\n",
    "# del cond_name[2]\n",
    "# del conditions[2]\n",
    "\n",
    "sample = sample_batch(my_model.tokenizer, cond_list, conditions)\n",
    "\n",
    "input_ids = sample[0].cuda()\n",
    "condition_string = sample[1]  \n",
    "input_len = len(input_ids)\n",
    "\n",
    "max_len = 70\n",
    "for _ in range(max_len):\n",
    "    model_out = my_model.model_feeding(input_ids) # (batch, seq_len, emb_dim)\n",
    "    pred_idx = model_out.argmax(1)[-1]        \n",
    "    if pred_idx == my_model.tokenizer.eos_token_id:\n",
    "        break            \n",
    "    input_ids = torch.cat((input_ids, pred_idx.unsqueeze(0)), 0)        \n",
    "\n",
    "out_sen = my_model.tokenizer.decode(input_ids[input_len:])\n",
    "print(cond_list)\n",
    "print(conditions)\n",
    "print(out_sen)\n",
    "\n",
    "if name is not None:\n",
    "    out_sen = out_sen.replace(placeholder_name, name)\n",
    "if eatType is not None:\n",
    "    out_sen = out_sen.replace(placeholder_eatType, eatType)\n",
    "if food is not None:\n",
    "    out_sen = out_sen.replace(placeholder_food, food)\n",
    "if priceRange is not None:\n",
    "    out_sen = out_sen.replace(placeholder_priceRange, priceRange)\n",
    "if customer_rating is not None:\n",
    "    out_sen = out_sen.replace(placeholder_customer_rating, customer_rating)\n",
    "if area is not None:\n",
    "    out_sen = out_sen.replace(placeholder_area, area)  \n",
    "if near is not None:\n",
    "    out_sen = out_sen.replace(placeholder_near, near)\n",
    "print(out_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<name>', '<food>', '<customer rating>', '<area>', '<familyFriendly>'],\n",
       " ['Clowns', 'Fast food', 'average', 'city centre', 'yes'])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_list, conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delexicalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class e2eDataset(Dataset):\n",
    "    def __init__(self, csv_file1, csv_file2, tokenizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): csv 파일의 경로\n",
    "        \"\"\"\n",
    "        self.dataset1 = pd.read_csv(csv_file1)\n",
    "        self.dataset2 = pd.read_csv(csv_file2)\n",
    "        \n",
    "        self.columns1 = self.dataset1.columns\n",
    "        self.columns2 = self.dataset2.columns\n",
    "        \n",
    "        self.conditions = list(self.dataset1[self.columns1[0]]) + list(self.dataset2[self.columns2[0]])\n",
    "        self.sentences = list(self.dataset1[self.columns1[1]]) + list(self.dataset2[self.columns2[1]])\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.typ_list = {}\n",
    "        for k in range(len(self.conditions)):\n",
    "            cond_set = self.conditions[k].split(',')\n",
    "            for m in range(len(cond_set)):\n",
    "                cond_set[m] = cond_set[m].strip()\n",
    "                pos = cond_set[m].index('[')\n",
    "                if cond_set[m][:pos] in self.typ_list.keys():\n",
    "                    self.typ_list[cond_set[m][:pos]].add(cond_set[m][pos+1:-1])\n",
    "                else:            \n",
    "                    self.typ_list[cond_set[m][:pos]] = {cond_set[m][pos+1:-1]}        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.conditions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sen = self.sentences[idx]\n",
    "        \n",
    "        cond = self.conditions[idx]\n",
    "        cond_set = cond.split(',')        \n",
    "        condition_string = ''\n",
    "        \n",
    "        \n",
    "        p = random.random()\n",
    "\n",
    "        if p > 0.3: # 70%\n",
    "            for m in range(len(cond_set)):\n",
    "                cond_set[m] = cond_set[m].strip()\n",
    "                pos = cond_set[m].index('[')\n",
    "\n",
    "                condition_string += '<' + cond_set[m][:pos] + '>' + cond_set[m][pos+1:-1] + ' '\n",
    "        else: # p <= 0.3 / 30%\n",
    "            nochange_list = ['priceRange', 'customer rating', 'familyFriendly']\n",
    "            for m in range(len(cond_set)):\n",
    "                cond_set[m] = cond_set[m].strip()\n",
    "                \n",
    "                pos = cond_set[m].index('[')\n",
    "                if cond_set[m][:pos] not in nochange_list:\n",
    "                    placeholder = '<' + cond_set[m][:pos] + '>'\n",
    "                    condition_string += placeholder + ' '\n",
    "                    sen = sen.replace(cond_set[m][pos+1:-1], placeholder)        \n",
    "                else:\n",
    "                    condition_string += '<' + cond_set[m][:pos] + '>' + cond_set[m][pos+1:-1] + ' '\n",
    "        \n",
    "        input_string = condition_string + '<START>' + sen\n",
    "        input_ids = torch.tensor(self.tokenizer.encode(input_string, add_special_tokens=True))\n",
    "        \n",
    "        label_string = sen + ' <|endoftext|>'\n",
    "        label_ids = torch.tensor(self.tokenizer.encode(label_string, add_special_tokens=True))\n",
    "\n",
    "        return input_string, input_ids, label_ids    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<name>Fitzbillies <priceRange>moderate <customer rating>1 out of 5 <familyFriendly>yes <near>Express by Holiday Inn <START>Fitzbillies is a kids friendly place located a few steps of the Express by Holiday Inn. Its prices are moderates, and it has  a poor rating  between its clients.\n"
     ]
    }
   ],
   "source": [
    "e2e_dataset = e2eDataset(csv_file1='dataset/trainset.csv', csv_file2='dataset/devset.csv', tokenizer=my_model.tokenizer)\n",
    "print(e2e_dataset[200][0])\n",
    "# print(e2e_dataset.typ_list.keys())\n",
    "# print(e2e_dataset.typ_list)\n",
    "# priceRange, customer rating, familyFriendly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dev = open('f_dev.txt', 'r')\n",
    "f_pred = open('f_pred.txt', 'r')\n",
    "f_dev_dataset = f_dev.readlines()\n",
    "f_pred_dataset = f_pred.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5218, 547)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_dev_dataset), len(f_pred_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4672, 547)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[x for x in f_dev_dataset if x != '\\n']\n",
    "data2=[x for x in f_pred_dataset if x != '\\n']\n",
    "len(data), len(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5218"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4672+546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dev = open('./e2e-metrics/example-inputs/devel-conc.txt', 'r')\n",
    "f_pred = open('./e2e-metrics/example-inputs/baseline-output.txt', 'r')\n",
    "f_dev_dataset = f_dev.readlines()\n",
    "f_pred_dataset = f_pred.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_dev_dataset), len(f_pred_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[x for x in f_dev_dataset if x != '\\n']\n",
    "data2=[x for x in f_pred_dataset if x != '\\n']\n",
    "len(data), len(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15699480814634292"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "p=random.random()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
